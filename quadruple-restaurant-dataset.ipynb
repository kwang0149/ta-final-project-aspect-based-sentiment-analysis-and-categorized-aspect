{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import findfile\n",
    "import pandas as pd\n",
    "import json\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hongk\\Documents\\GitHub\\ta-final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv-absa-3.9\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 0.9.10.post1 of metric_visualizer is outdated. Version 0.9.13.post1 was released Wednesday May 01, 2024.\n",
      "[2024-06-07 19:50:33] (2.4.1.post1) \u001b[31mPyABSA(2.4.1.post1): If your code crashes on Colab, please use the GPU runtime. Then run \"pip install pyabsa[dev] -U\" and restart the kernel.\n",
      "Or if it does not work, you can use v1.x versions, e.g., pip install pyabsa<2.0 -U\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING: When you fails to load a checkpoint, e.g., Unexpected key(s),\n",
      "Try to downgrade transformers<=4.29.0.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hongk\\Documents\\GitHub\\ta-final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv-absa-3.9\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:246: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n",
      "c:\\Users\\hongk\\Documents\\GitHub\\ta-final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv-absa-3.9\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:326: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n",
      "C:\\Users\\hongk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\pool.py:265: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from pyabsa import ABSAInstruction as absa_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"multitask\"\n",
    "experiment_name = \"instruction\"\n",
    "# model_checkpoint = \"google/flan-t5-base\"\n",
    "model_checkpoint = \"kevinscaria/ate_tk-instruct-base-def-pos-neg-neut-combined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Name:  instruction\n",
      "Model output path:  checkpoints\\multitask\\kevinscariaate_tk-instruct-base-def-pos-neg-neut-combined-instruction\n"
     ]
    }
   ],
   "source": [
    "print(\"Experiment Name: \", experiment_name)\n",
    "model_out_path = \"checkpoints\"\n",
    "model_out_path = os.path.join(\n",
    "    model_out_path, task_name, f\"{model_checkpoint.replace('/', '')}-{experiment_name}\"\n",
    ")\n",
    "print(\"Model output path: \", model_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_train_file_path = \"./ABSADatasets/datasets/acos_datasets/504.Restaurant16/\"\n",
    "id_test_file_path = \"./ABSADatasets/datasets/acos_datasets/504.Restaurant16/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ABSADatasets/datasets/acos_datasets/504.Restaurant16/rest16_quad_train.tsv.jsonl\n",
      "./ABSADatasets/datasets/acos_datasets/504.Restaurant16/rest16_quad_test.tsv.jsonl\n"
     ]
    }
   ],
   "source": [
    "id_tr_df = absa_instruction.data_utils.read_json(id_train_file_path, \"train\")\n",
    "id_te_df = absa_instruction.data_utils.read_json(id_test_file_path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>judging from previous posts this used to be a ...</td>\n",
       "      <td>[{'aspect': 'place', 'opinion': 'not any longe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we , there were four of us , arrived at noon -...</td>\n",
       "      <td>[{'aspect': 'staff', 'opinion': 'rude', 'polar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they never brought us complimentary noodles , ...</td>\n",
       "      <td>[{'aspect': 'NULL', 'opinion': 'NULL', 'polari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[{'aspect': 'food', 'opinion': 'lousy', 'polar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after all that , they complained to me about t...</td>\n",
       "      <td>[{'aspect': 'NULL', 'opinion': 'complained', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>i ca n ' t believe that it was , but please pu...</td>\n",
       "      <td>[{'aspect': 'NULL', 'opinion': 'NULL', 'polari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>the waitress came to check in on us every few ...</td>\n",
       "      <td>[{'aspect': 'waitress', 'opinion': 'NULL', 'po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>i could n ' t ignore the fact that she reach o...</td>\n",
       "      <td>[{'aspect': 'NULL', 'opinion': 'NULL', 'polari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>she then put the check down without asking if ...</td>\n",
       "      <td>[{'aspect': 'NULL', 'opinion': 'NULL', 'polari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>i wish i could like this place more , and i wi...</td>\n",
       "      <td>[{'aspect': 'place', 'opinion': 'NULL', 'polar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1530 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     judging from previous posts this used to be a ...   \n",
       "1     we , there were four of us , arrived at noon -...   \n",
       "2     they never brought us complimentary noodles , ...   \n",
       "3     the food was lousy - too sweet or too salty an...   \n",
       "4     after all that , they complained to me about t...   \n",
       "...                                                 ...   \n",
       "1525  i ca n ' t believe that it was , but please pu...   \n",
       "1526  the waitress came to check in on us every few ...   \n",
       "1527  i could n ' t ignore the fact that she reach o...   \n",
       "1528  she then put the check down without asking if ...   \n",
       "1529  i wish i could like this place more , and i wi...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [{'aspect': 'place', 'opinion': 'not any longe...  \n",
       "1     [{'aspect': 'staff', 'opinion': 'rude', 'polar...  \n",
       "2     [{'aspect': 'NULL', 'opinion': 'NULL', 'polari...  \n",
       "3     [{'aspect': 'food', 'opinion': 'lousy', 'polar...  \n",
       "4     [{'aspect': 'NULL', 'opinion': 'complained', '...  \n",
       "...                                                 ...  \n",
       "1525  [{'aspect': 'NULL', 'opinion': 'NULL', 'polari...  \n",
       "1526  [{'aspect': 'waitress', 'opinion': 'NULL', 'po...  \n",
       "1527  [{'aspect': 'NULL', 'opinion': 'NULL', 'polari...  \n",
       "1528  [{'aspect': 'NULL', 'opinion': 'NULL', 'polari...  \n",
       "1529  [{'aspect': 'place', 'opinion': 'NULL', 'polar...  \n",
       "\n",
       "[1530 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_tr_df = pd.DataFrame(id_tr_df)\n",
    "id_tr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yum !</td>\n",
       "      <td>[{'aspect': 'NULL', 'opinion': 'yum', 'polarit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>serves really good sushi .</td>\n",
       "      <td>[{'aspect': 'sushi', 'opinion': 'good', 'polar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not the biggest portions but adequate .</td>\n",
       "      <td>[{'aspect': 'portions', 'opinion': 'not the bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green tea creme brulee is a must !</td>\n",
       "      <td>[{'aspect': 'green tea creme brulee', 'opinion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it has great sushi and even better service .</td>\n",
       "      <td>[{'aspect': 'sushi', 'opinion': 'great', 'pola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>insultingly overpriced</td>\n",
       "      <td>[{'aspect': 'NULL', 'opinion': 'overpriced', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>- mediocre service / quality</td>\n",
       "      <td>[{'aspect': 'service', 'opinion': 'mediocre', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>to their credit they removed the dish from the...</td>\n",
       "      <td>[{'aspect': 'manager', 'opinion': 'NULL', 'pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>two rascally kids were seated near us for the ...</td>\n",
       "      <td>[{'aspect': 'NULL', 'opinion': 'NULL', 'polari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>all considered , i have to say that ray ' s bo...</td>\n",
       "      <td>[{'aspect': 'ray ' s boathouse', 'opinion': 'N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0                                                yum !   \n",
       "1                           serves really good sushi .   \n",
       "2              not the biggest portions but adequate .   \n",
       "3                   green tea creme brulee is a must !   \n",
       "4         it has great sushi and even better service .   \n",
       "..                                                 ...   \n",
       "578                             insultingly overpriced   \n",
       "579                       - mediocre service / quality   \n",
       "580  to their credit they removed the dish from the...   \n",
       "581  two rascally kids were seated near us for the ...   \n",
       "582  all considered , i have to say that ray ' s bo...   \n",
       "\n",
       "                                                labels  \n",
       "0    [{'aspect': 'NULL', 'opinion': 'yum', 'polarit...  \n",
       "1    [{'aspect': 'sushi', 'opinion': 'good', 'polar...  \n",
       "2    [{'aspect': 'portions', 'opinion': 'not the bi...  \n",
       "3    [{'aspect': 'green tea creme brulee', 'opinion...  \n",
       "4    [{'aspect': 'sushi', 'opinion': 'great', 'pola...  \n",
       "..                                                 ...  \n",
       "578  [{'aspect': 'NULL', 'opinion': 'overpriced', '...  \n",
       "579  [{'aspect': 'service', 'opinion': 'mediocre', ...  \n",
       "580  [{'aspect': 'manager', 'opinion': 'NULL', 'pol...  \n",
       "581  [{'aspect': 'NULL', 'opinion': 'NULL', 'polari...  \n",
       "582  [{'aspect': 'ray ' s boathouse', 'opinion': 'N...  \n",
       "\n",
       "[583 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_te_df = pd.DataFrame(id_te_df)\n",
    "id_te_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = absa_instruction.data_utils.InstructDatasetLoader(id_tr_df, id_te_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loader.train_df_id is not None:\n",
    "    loader.train_df_id = loader.prepare_instruction_dataloader(loader.train_df_id)\n",
    "if loader.test_df_id is not None:\n",
    "    loader.test_df_id = loader.prepare_instruction_dataloader(loader.test_df_id)\n",
    "# if loader.train_df_ood is not None:\n",
    "#     loader.train_df_ood = loader.prepare_instruction_dataloader(loader.train_df_ood)\n",
    "if loader.test_df_ood is not None:\n",
    "    loader.test_df_ood = loader.prepare_instruction_dataloader(loader.test_df_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-07 19:59:25] (2.4.1.post1) ********** \u001b[32mAvailable ACOS model checkpoints for Version:2.4.1.post1 (this version)\u001b[0m **********\n",
      "[2024-06-07 19:59:25] (2.4.1.post1) ********** \u001b[32mAvailable ACOS model checkpoints for Version:2.4.1.post1 (this version)\u001b[0m **********\n",
      "[2024-06-07 19:59:25] (2.4.1.post1) \u001b[31mCheckpoint:kevinscaria/ate_tk-instruct-base-def-pos-neg-neut-combined is not found, you can raise an issue for requesting shares of checkpoints\u001b[0m\n",
      "[2024-06-07 19:59:25] (2.4.1.post1) No checkpoint found in Model Hub for task: kevinscaria/ate_tk-instruct-base-def-pos-neg-neut-combined\n"
     ]
    }
   ],
   "source": [
    "# Create T5 utils object\n",
    "t5_exp = absa_instruction.model.T5Generator(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5601/5601 [00:00<00:00, 9751.39 examples/s]\n",
      "Map: 100%|██████████| 2135/2135 [00:00<00:00, 10544.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Dataset\n",
    "id_ds, id_tokenized_ds, ood_ds, ood_tokenzed_ds = loader.create_datasets(\n",
    "    t5_exp.tokenize_function_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5601/5601 [00:00<00:00, 11079.75 examples/s]\n",
      "Map: 100%|██████████| 2135/2135 [00:00<00:00, 11008.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "id_ds, id_tokenized_ds, ood_ds, ood_tokenzed_ds = loader.create_datasets(\n",
    "    t5_exp.tokenize_function_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    \"output_dir\": model_out_path,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"num_train_epochs\": 8,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"push_to_hub\": False,\n",
    "    \"eval_accumulation_steps\": 1,\n",
    "    \"predict_with_generate\": True,\n",
    "    \"logging_steps\": 1000000000,\n",
    "    \"use_mps_device\": False,\n",
    "    # 'fp16': True,\n",
    "    \"fp16\": False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer device: cuda:0\n",
      "\n",
      "Model training started ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11208 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  2%|▏         | 205/11208 [1:08:53<301:43:07, 98.72s/it] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_trainer \u001b[38;5;241m=\u001b[39m t5_exp\u001b[38;5;241m.\u001b[39mtrain(id_tokenized_ds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtraining_args)\n",
      "File \u001b[1;32mc:\\Users\\hongk\\Documents\\GitHub\\ta-final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv-absa-3.9\\lib\\site-packages\\pyabsa\\tasks\\ABSAInstruction\\model.py:73\u001b[0m, in \u001b[0;36mT5Generator.train\u001b[1;34m(self, tokenized_datasets, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel training started ....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Save best model\u001b[39;00m\n\u001b[0;32m     76\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[1;32mc:\\Users\\hongk\\Documents\\GitHub\\ta-final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv-absa-3.9\\lib\\site-packages\\transformers\\trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1659\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1661\u001b[0m )\n\u001b[1;32m-> 1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hongk\\Documents\\GitHub\\ta-final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv-absa-3.9\\lib\\site-packages\\transformers\\trainer.py:1996\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1994\u001b[0m     optimizer_was_run \u001b[38;5;241m=\u001b[39m scale_before \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m scale_after\n\u001b[0;32m   1995\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1996\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed:\n\u001b[0;32m   1999\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\hongk\\Documents\\GitHub\\ta-final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv-absa-3.9\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hongk\\Documents\\GitHub\\ta-final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv-absa-3.9\\lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hongk\\Documents\\GitHub\\ta-final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv-absa-3.9\\lib\\site-packages\\transformers\\optimization.py:466\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;66;03m# Just adding the square of the weights to the loss function is *not*\u001b[39;00m\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;66;03m# the correct way of using L2 regularization/weight decay with Adam,\u001b[39;00m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;66;03m# since that will interact with the m and v parameters in strange ways.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;66;03m# of the weights to the loss with plain (non-momentum) SGD.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Add weight decay at the end (fixed version)\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m--> 466\u001b[0m             \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model_trainer = t5_exp.train(id_tokenized_ds, **training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction labels - Training set\n",
    "id_tr_pred_labels = t5_exp.get_labels(\n",
    "    predictor=model_trainer,\n",
    "    tokenized_dataset=id_tokenized_ds,\n",
    "    sample_set=\"train\",\n",
    "    batch_size=16,\n",
    ")\n",
    "id_tr_labels = [i.strip() for i in id_ds[\"train\"][\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_te_pred_labels = t5_exp.get_labels(\n",
    "    predictor=model_trainer,\n",
    "    tokenized_dataset=id_tokenized_ds,\n",
    "    sample_set=\"test\",\n",
    "    batch_size=16,\n",
    ")\n",
    "id_te_labels = [i.strip() for i in id_ds[\"test\"][\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = t5_exp.get_classic_metrics(id_tr_labels, id_tr_pred_labels)\n",
    "print(\"----------------------- Classic Training Set Metrics -----------------------\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = t5_exp.get_classic_metrics(id_te_labels, id_te_pred_labels)\n",
    "print(\"----------------------- Classic Testing Set Metrics -----------------------\")\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-absa-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
