{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA GPU found in your device\n",
      "Version 0.9.9 of metric_visualizer is outdated. Version 0.9.10 was released Sunday January 21, 2024.\n",
      "[2024-03-12 16:08:16] (2.3.3) \u001b[31mPyABSA(2.3.3): If your code crashes on Colab, please use the GPU runtime. Then run \"pip install pyabsa[dev] -U\" and restart the kernel.\n",
      "Or if it does not work, you can use v1.x versions, e.g., pip install pyabsa<2.0 -U\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING: When you fails to load a checkpoint, e.g., Unexpected key(s),\n",
      "Try to downgrade transformers<=4.29.0.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyabsa import ABSAInstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hongk\\AppData\\Local\\Programs\\Python\\Python38\\lib\\multiprocessing\\pool.py:265: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "    generator = ABSAInstruction.ABSAGenerator(\n",
    "        \"checkpoints/multitask/googleflan-t5-base-instruction/checkpoint-5604\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    example = [\n",
    "        \"The food is good, but the service is bad.\",\n",
    "        \"The toilet is so dirty, but I like the chicken and soup\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hongk\\OneDrive\\Documents\\Bangkit\\final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "c:\\users\\hongk\\OneDrive\\Documents\\Bangkit\\final-project-aspect-based-sentiment-analysis-and-categorized-aspect\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (128) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The food is good, but the service is bad.', 'Quadruples': [{'aspect': 'food', 'polarity': 'positive', 'opinion': 'good', 'category': 'FOOD#QUALITY'}, {'aspect': 'service', 'polarity': 'negative', 'opinion': 'bad', 'category': 'SERVICE#GENERAL'}]}\n",
      "{'text': 'The food is good, but the service is bad.', 'Quadruples': [{'aspect': 'food', 'polarity': 'positive', 'opinion': 'good', 'category': 'FOOD#QUALITY'}, {'aspect': 'service', 'polarity': 'negative', 'opinion': 'bad', 'category': 'SERVICE#GENERAL'}]}\n",
      "{'text': 'The toilet is so dirty, but I like the chicken and soup', 'Quadruples': [{'aspect': 'toilet', 'polarity': 'negative', 'opinion': 'dirty', 'category': 'SERVICE#GENERAL'}, {'aspect': 'chicken and soup', 'polarity': 'positive', 'opinion': 'like', 'category': 'FOOD#QUALITY'}]}\n",
      "{'text': 'The toilet is so dirty, but I like the chicken and soup', 'Quadruples': [{'aspect': 'toilet', 'polarity': 'negative', 'opinion': 'dirty', 'category': 'SERVICE#GENERAL'}, {'aspect': 'chicken and soup', 'polarity': 'positive', 'opinion': 'like', 'category': 'FOOD#QUALITY'}]}\n"
     ]
    }
   ],
   "source": [
    "    for example in example:\n",
    "        result = generator.predict(example)\n",
    "        print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
